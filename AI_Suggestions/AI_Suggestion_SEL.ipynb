{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding:utf-8\n",
    "###########import packages##########\n",
    "import shap\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.constraints import max_norm\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense \n",
    "from keras.layers import Dropout \n",
    "from keras.models import Model\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.wrappers.scikit_learn import KerasClassifier \n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.constraints import maxnorm \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xgboost \n",
    "import lightgbm\n",
    "import catboost\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import plot_importance\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import ensemble\n",
    "from sklearn.tree import ExtraTreeRegressor\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "from sklearn import tree\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import r2_score\n",
    "from keras.models import Model,load_model\n",
    "import shap\n",
    "from catboost import *\n",
    "%matplotlib\n",
    "###########wrapping root mean square error for later calls##########\n",
    "def compute_mae_mse_rmse(target,prediction):\n",
    "    error = []\n",
    "    for i in range(len(target)):\n",
    "        error.append(target[i] - prediction[i])\n",
    "    squaredError = []\n",
    "    absError = []\n",
    "    for val in error:\n",
    "        squaredError.append(val * val)  # target-prediction之差平方\n",
    "        absError.append(abs(val))  # 误差绝对值\n",
    "    mae=sum(absError)/len(absError)  # 平均绝对误差MAE\n",
    "    mse=sum(squaredError)/len(squaredError)  # 均方误差MSE\n",
    "    RMSE=np.sqrt(sum(squaredError)/len(squaredError))\n",
    "    R2=r2_score(target,prediction)\n",
    "    return mae,mse,RMSE,R2\n",
    "###########loading data##########\n",
    "fdata=pd.read_csv('datatest.csv',encoding=\"gbk\")\n",
    "raw_data=fdata.loc[:,['Dielectric Constant (C  N-1 M-2)',#0\n",
    "                      'Flash Point(℃)',#1\n",
    "                      'Stirring Method (0 for Mechanical Stirring 1 for Ultrasound)',#2\n",
    "                      'Flow Rate (mL min-1)',#3\n",
    "                      'Water Content (wt%)',#4\n",
    "                      'Anodic Platinum Loading Amount (mgPt cm-2)',#5\n",
    "                      'Cathodic Platinum Loading Amount (mgPt cm-2)',#6\n",
    "                      'I/C',#7\n",
    "                      'Cell Temperature (℃)',#8\n",
    "                      'Anode Flow Rate (sccm)',#9\n",
    "                      'Cathode Flow Rate (sccm)',#10\n",
    "                      'Solid Content (wt%)',#11\n",
    "                      'Backpressure (Mpa)',#18\n",
    "                      'Pt Consumption per kW@0.65V (mgpt kW-1)'#19\n",
    "                        ]]\n",
    "\n",
    "\n",
    "\n",
    "###########defining a wrapper function for later call from each machine learning algorithms##########\n",
    "raw_input=raw_data.iloc[:,0:13]\n",
    "raw_output=raw_data.iloc[:,13]\n",
    "raw_input_global=raw_data.iloc[:,0:13]\n",
    "raw_output_global=raw_data.iloc[:,13]\n",
    "X=raw_input.values.astype(np.float32)\n",
    "y=raw_output.values.astype(np.float32)\n",
    "###########wrap up fuction for later call for OPTIMIZATION##########\n",
    "def evaluate(pre_2,real_2):\n",
    "    pre_2=np.array(pre_2)\n",
    "    real_2=np.array(real_2)\n",
    "    pre_2_series=pd.Series(pre_2)\n",
    "    real_2_series=pd.Series(real_2)\n",
    "    return rmse(pre_2,real_2), round(pre_2_series.corr(real_2_series), 3)\n",
    "def compare(list_name,limit):\n",
    "    judge=1\n",
    "    for a in list_name:\n",
    "        if a < limit:\n",
    "            judge=judge*1\n",
    "        else:\n",
    "            judge=judge*0\n",
    "    return judge\n",
    "def generate_arrays_from_file(path):\n",
    "    while True:\n",
    "        with open(path) as f:\n",
    "            for line in f:\n",
    "                # create numpy arrays of input data\n",
    "                # and labels, from each line in the file\n",
    "                x1, x2, y = process_line(line)\n",
    "                yield ({'input_1': x1, 'input_2': x2}, {'output': y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ANN=load_model('ANN_PTUTIL_1_sel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdpbox import pdp\n",
    "def plot_pdp_interact_ANN(model, df, f_list, cluster_flag=False, nb_clusters=None, lines_flag=False):\n",
    "    \n",
    "    # Create the data that we will plot\n",
    "    inter1 = pdp.pdp_interact(model, df, model_features=df.columns.tolist(), features=f_list,num_grid_points=[20,20])\n",
    "    # plot it\n",
    "    settings = {\n",
    "            'contour_color':  'white',\n",
    "            'font_family': 'Arial',\n",
    "            # matplotlib color map for interact plot\n",
    "            'cmap': 'viridis',\n",
    "            # fill alpha for interact plot\n",
    "            'inter_fill_alpha': 0.8,\n",
    "            # fontsize for interact plot text\n",
    "            'inter_fontsize': 7,\n",
    "        }\n",
    "    pdp.pdp_interact_plot(\n",
    "    pdp_interact_out=inter1, feature_names=f_list, plot_type='contour',figsize=(10,10),x_quantile=True, plot_pdp=True,plot_params=settings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pdp_single(model, df, feature, cluster_flag=False, nb_clusters=None, lines_flag=False):\n",
    "    \n",
    "    # Create the data that we will plot\n",
    "    pdp_goals = pdp.pdp_isolate(model=model, dataset=df, model_features=df.columns.tolist(), feature=feature)\n",
    "\n",
    "    # plot it\n",
    "    pdp.pdp_plot(pdp_goals, feature, cluster=cluster_flag, n_cluster_centers=nb_clusters, plot_lines=lines_flag)\n",
    "    plt.show()\n",
    "def plot_pdp_single_else(model,param,feature):\n",
    "    grid = GridSearchCV(model,param_grid=param,cv=5)\n",
    "    grid.fit(X_train,y_train)\n",
    "    best_model=grid.best_estimator_\n",
    "    # Create the data that we will plot\n",
    "    plot_pdp_single(best_model,raw_input,feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_list1=['Dielectric Constant (C  N-1 M-2)',\n",
    "                      'Flash Point(℃)']\n",
    "inter_list2=['Anodic Platinum Loading Amount (mgPt cm-2)',#9\n",
    "                      'Cathodic Platinum Loading Amount (mgPt cm-2)']\n",
    "inter_list3=['Stirring Method (0 for Mechanical Stirring 1 for Ultrasound)',\n",
    "'Solid Content (wt%)']\n",
    "inter_list4=['I/C', 'Water Content (wt%)']\n",
    "# plot_pdp_interact_ANN(model_ANN,raw_input,inter_list1)\n",
    "# plot_pdp_interact_ANN(model_ANN,raw_input,inter_list2)\n",
    "# plot_pdp_interact_ANN(model_ANN,raw_input,inter_list3)\n",
    "plot_pdp_interact_ANN(model_ANN,raw_input,inter_list4)\n",
    "# plot_pdp_single(model_ANN,raw_input,'Flow Rate (mL min-1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import plot_partial_dependence\n",
    "from sklearn.utils import validation\n",
    "def pdp_plot_2d(model,param,f_index):\n",
    "    print('start')\n",
    "    grid = GridSearchCV(model,param_grid=param,cv=5)\n",
    "    grid.fit(X_train,y_train)\n",
    "    best_model=grid.best_estimator_    \n",
    "    validation.check_is_fitted(estimator=best_model)\n",
    "    my_plots =plot_partial_dependence(best_model, features=[f_index], X=raw_input, percentiles=(0, 1))\n",
    "def pdp_plot_2d_XG_CAT(model,param,f_index):\n",
    "    print('start')\n",
    "    grid = GridSearchCV(model,param_grid=param,cv=5)\n",
    "    grid.fit(X_train,y_train)\n",
    "    best_model=grid.best_estimator_\n",
    "    best_model.dummy_ = \"dummy\"\n",
    "    validation.check_is_fitted(estimator=best_model)\n",
    "    my_plots =plot_partial_dependence(best_model, features=[f_index], X=raw_input, percentiles=(0, 1))\n",
    "def pdp_plot_2d_ANN(model,f_index):\n",
    "    print('start')\n",
    "    model.dummy_ = \"dummy\"\n",
    "    print(type(model))\n",
    "    validation.check_is_fitted(estimator=model)\n",
    "    my_plots =plot_partial_dependence(model, features=[f_index], X=raw_input, percentiles=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_PRINT_ANN(DC,FP,SM,FR,WC,AL,CL,IC,SC,model):\n",
    "    raw_median=raw_data.median()\n",
    "    user_input1=raw_median[0:13]    \n",
    "    dict_result={}    \n",
    "    user_input1.iloc[0]=DC\n",
    "    user_input1.iloc[1]=FP\n",
    "    user_input1.iloc[2]=SM\n",
    "    user_input1.iloc[3]=FR\n",
    "    user_input1.iloc[4]=WC\n",
    "    user_input1.iloc[5]=AL\n",
    "    user_input1.iloc[6]=CL\n",
    "    user_input1.iloc[7]=IC\n",
    "    user_input1.iloc[8]=80\n",
    "    user_input1.iloc[9]=300\n",
    "    user_input1.iloc[10]=1500\n",
    "    user_input1.iloc[11]=SC\n",
    "    user_input1.iloc[12]=0.2\n",
    "    standardized_user_input1=(user_input1-np.mean(raw_data,axis=0)[0:13])/np.std(raw_data,axis=0)[0:13]\n",
    "    data_test_input1=standardized_user_input1\n",
    "    data_test_input1=pd.DataFrame(data_test_input1)\n",
    "    data_test_input1=data_test_input1.T\n",
    "    data_test_param1=data_test_input1.values.astype(np.float32)\n",
    "    predict_ann=model.predict(data_test_param1)\n",
    "    ###########result output##########\n",
    "    predict_ann=predict_ann*np.std(raw_output_global,axis=0)+np.mean(raw_output_global,axis=0)\n",
    "    x_prediction_ann=predict_ann.astype(np.float32)\n",
    "    x_prediction_ann=x_prediction_ann.tolist()\n",
    "    x_prediction_ann=x_prediction_ann[0]\n",
    "#     print(type(x_prediction_ann[0]))\n",
    "#     dict_result.update({x_prediction_ann[0]:{'Dielectric Constant (C  N-1 M-2)':DC,'Flash Point(℃)':FP}})\n",
    "    print(DC,FP,SM,FR,WC,AL,CL,IC,SC,x_prediction_ann[0])\n",
    "\n",
    "    return x_prediction_ann[0], dict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_PRINT_XG(DC,FP,SM,FR,WC,AL,CL,IC,SC,model):\n",
    "    raw_median=raw_data.median()\n",
    "    user_input1=raw_median[0:13]    \n",
    "    dict_result={}    \n",
    "    user_input1.iloc[0]=DC\n",
    "    user_input1.iloc[1]=FP\n",
    "    user_input1.iloc[2]=SM\n",
    "    user_input1.iloc[3]=FR\n",
    "    user_input1.iloc[4]=WC\n",
    "    user_input1.iloc[5]=AL\n",
    "    user_input1.iloc[6]=CL\n",
    "    user_input1.iloc[7]=IC\n",
    "    user_input1.iloc[8]=80\n",
    "    user_input1.iloc[9]=300\n",
    "    user_input1.iloc[10]=1500\n",
    "    user_input1.iloc[11]=SC\n",
    "    user_input1.iloc[12]=0.2\n",
    "    data_test_input1=pd.DataFrame(user_input1)\n",
    "    data_test_input1=data_test_input1.T\n",
    "#     data_test_param1=data_test_input1.values.astype(np.float32)\n",
    "    predict_ann=model.predict(data_test_input1)\n",
    "    \n",
    "    x_prediction_ann=predict_ann.astype(np.float32)\n",
    "#     print(type(x_prediction_ann[0]))\n",
    "#     dict_result.update({x_prediction_ann[0]:{'Dielectric Constant (C  N-1 M-2)':DC,'Flash Point(℃)':FP}})\n",
    "    print(DC,FP,SM,FR,WC,AL,CL,IC,SC,x_prediction_ann[0])\n",
    "\n",
    "    return x_prediction_ann, dict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_PRINT_OTHER(DC,FP,SM,FR,WC,AL,CL,IC,SC,model):\n",
    "    raw_median=raw_data.median()\n",
    "    user_input1=raw_median[0:13]    \n",
    "    dict_result={}    \n",
    "    user_input1.iloc[0]=DC\n",
    "    user_input1.iloc[1]=FP\n",
    "    user_input1.iloc[2]=SM\n",
    "    user_input1.iloc[3]=FR\n",
    "    user_input1.iloc[4]=WC\n",
    "    user_input1.iloc[5]=AL\n",
    "    user_input1.iloc[6]=CL\n",
    "    user_input1.iloc[7]=IC\n",
    "    user_input1.iloc[8]=80\n",
    "    user_input1.iloc[9]=300\n",
    "    user_input1.iloc[10]=1500\n",
    "    user_input1.iloc[11]=SC\n",
    "    user_input1.iloc[12]=0.2\n",
    "    data_test_input1=pd.DataFrame(user_input1)\n",
    "    data_test_input1=data_test_input1.T\n",
    "    data_test_param1=data_test_input1.values.astype(np.float32)\n",
    "    predict_ann=model.predict(data_test_param1)\n",
    "    \n",
    "    x_prediction_ann=predict_ann.astype(np.float32)\n",
    "#     print(type(x_prediction_ann[0]))\n",
    "#     dict_result.update({x_prediction_ann[0]:{'Dielectric Constant (C  N-1 M-2)':DC,'Flash Point(℃)':FP}})\n",
    "    print(DC,FP,SM,FR,WC,AL,CL,IC,SC,x_prediction_ann[0])\n",
    "\n",
    "    return x_prediction_ann, dict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearch(model,param,algorithm_name):\n",
    "    grid = GridSearchCV(model,param_grid=param,cv=5)\n",
    "    grid.fit(X_train,y_train)\n",
    "    best_model=grid.best_estimator_\n",
    "    result = best_model.predict(X_test)\n",
    "    x_prediction_07=result\n",
    "    y_real_07=y_test.values\n",
    "    x_prediction_07_series=pd.Series(x_prediction_07)\n",
    "    y_real_07_series=pd.Series(y_real_07)\n",
    "    \n",
    "    result_train = best_model.predict(X_train)\n",
    "    x_prediction_07_train=result_train\n",
    "    y_real_07_train=y_train.values\n",
    "    x_prediction_07_series_train=pd.Series(x_prediction_07_train)\n",
    "    y_real_07_series_train=pd.Series(y_real_07_train)\n",
    "    \n",
    "    ###########evaluating the regression quality##########\n",
    "    corr_ann = round(x_prediction_07_series.corr(y_real_07_series), 5)\n",
    "    error_val= compute_mae_mse_rmse(x_prediction_07,y_real_07)\n",
    "    \n",
    "    corr_ann_train = round(x_prediction_07_series_train.corr(y_real_07_series_train), 5)\n",
    "    error_val_train= compute_mae_mse_rmse(x_prediction_07_train,y_real_07_train)\n",
    "    \n",
    "    print(algorithm_name)\n",
    "    print(best_model.feature_importances_)\n",
    "    print('Best Regressor:',grid.best_params_,'Best Score:', grid.best_score_)\n",
    "    print(error_val,'TEST R2',error_val[3],'TEST CORR',corr_ann)\n",
    "    print(error_val_train,'TRAIN R2',error_val_train[3],'TRAIN CORR',corr_ann_train)\n",
    "    x_y_x=np.arange(0,2.1,0.1)\n",
    "    x_y_y=np.arange(0,2.1,0.1)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.scatter(x_prediction_07,y_real_07,color='red',label=algorithm_name+' Test Set',alpha=0.75)\n",
    "    ax.scatter(x_prediction_07_train,y_real_07_train,color='blue',label=algorithm_name+' Training Set',alpha=0.25,marker=\"^\")\n",
    "    ax.plot(x_y_x,x_y_y)\n",
    "    plt.legend()\n",
    "    plt.xlabel(u\"Predicted_Pt_Consumption_per_kW@0.65V (mgpt kW-1)\")\n",
    "    plt.ylabel(u\"Real_Pt_Consumption_per_kW@0.65V (mgpt kW-1)\")\n",
    "    print('finished')\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_plot_interaction(model,param,algorithm_name,interacted_features):\n",
    "    print(algorithm_name)\n",
    "    SHAP_INPUT=raw_data.iloc[:,0:13]\n",
    "    SHAP_OUTPUT=raw_data.iloc[:,13]\n",
    "    grid = GridSearchCV(model,param_grid=param,cv=5)\n",
    "    grid.fit(X_train,y_train)\n",
    "    print('train finished')\n",
    "    best_model=grid.best_estimator_\n",
    "    X_SHAP=SHAP_INPUT.values.astype(np.float32)\n",
    "    y_SHAP=SHAP_OUTPUT.values.astype(np.float32)\n",
    "\n",
    "    if algorithm_name=='CatBoost':\n",
    "        shap_values = best_model.get_feature_importance(Pool(X_SHAP,y_SHAP), type=\"ShapValues\")\n",
    "        shap_values=shap_values[:,:-1]\n",
    "        \n",
    "#         shap_values = model.get_feature_importance(Pool(data[Xtrain.columns]),type=EFstrType.ShapValues,verbose=100)\n",
    "        interaction_values = best_model.get_feature_importance(Pool(SHAP_INPUT),type=EFstrType.ShapInteractionValues)\n",
    "        interaction_values=interaction_values[:,:-1,:-1]\n",
    "        shap.dependence_plot(interacted_features[0], shap_values, SHAP_INPUT,interaction_index= interacted_features[1])\n",
    "        shap.dependence_plot(interacted_features[1], shap_values, SHAP_INPUT,interaction_index= interacted_features[0])\n",
    "        shap.summary_plot(interaction_values,SHAP_INPUT, max_display=14)\n",
    "    elif algorithm_name=='Random Forest' or algorithm_name=='Extra Tree'or algorithm_name=='Decision Tree'or algorithm_name=='AdaBoost':\n",
    "        explainer = shap.TreeExplainer(best_model,SHAP_INPUT)\n",
    "        shap_values = explainer.shap_values(X_SHAP,check_additivity= False)        \n",
    "        interaction_values = shap.TreeExplainer(best_model).shap_interaction_values(SHAP_INPUT)        \n",
    "        shap.dependence_plot(interacted_features[0], shap_values, SHAP_INPUT,interaction_index= interacted_features[1])\n",
    "        shap.dependence_plot(interacted_features[1], shap_values, SHAP_INPUT,interaction_index= interacted_features[0])\n",
    "        shap.summary_plot(interaction_values,SHAP_INPUT, max_display=14)\n",
    "    else:\n",
    "        explainer = shap.TreeExplainer(best_model,SHAP_INPUT)\n",
    "        shap_values = explainer.shap_values(X_SHAP,check_additivity= False)\n",
    "        interaction_values = shap.TreeExplainer(best_model).shap_interaction_values(SHAP_INPUT)        \n",
    "        shap.dependence_plot(interacted_features[0], shap_values, SHAP_INPUT,interaction_index= interacted_features[1])\n",
    "        shap.dependence_plot(interacted_features[1], shap_values, SHAP_INPUT,interaction_index= interacted_features[0])\n",
    "        shap.summary_plot(interaction_values, SHAP_INPUT, max_display=14)\n",
    "def shap_plot_interaction_ANN(model,interacted_features):\n",
    "    SHAP_INPUT=raw_data.iloc[:,0:13]\n",
    "    SHAP_OUTPUT=raw_data.iloc[:,13]\n",
    "    X_SHAP=SHAP_INPUT.values.astype(np.float32)\n",
    "    y_SHAP=SHAP_OUTPUT.values.astype(np.float32)\n",
    "    explainer = shap.DeepExplainer(model,X_SHAP)\n",
    "    shap_values = explainer.shap_values(X_SHAP)\n",
    "    shap.dependence_plot(interacted_features[0], shap_values[0], SHAP_INPUT,interaction_index= interacted_features[1])\n",
    "    shap.dependence_plot(interacted_features[1], shap_values[0], SHAP_INPUT,interaction_index= interacted_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_plot_interaction_single(model,param,algorithm_name,interacted_feature):\n",
    "    print(algorithm_name)\n",
    "    SHAP_INPUT=raw_data.iloc[:,0:13]\n",
    "    SHAP_OUTPUT=raw_data.iloc[:,13]\n",
    "    grid = GridSearchCV(model,param_grid=param,cv=5)\n",
    "    grid.fit(X_train,y_train)\n",
    "    print('train finished')\n",
    "    best_model=grid.best_estimator_\n",
    "    X_SHAP=SHAP_INPUT.values.astype(np.float32)\n",
    "    y_SHAP=SHAP_OUTPUT.values.astype(np.float32)\n",
    "\n",
    "    if algorithm_name=='CatBoost':\n",
    "        shap_values = best_model.get_feature_importance(Pool(X_SHAP,y_SHAP), type=\"ShapValues\")\n",
    "        shap_values=shap_values[:,:-1]\n",
    "        \n",
    "#         shap_values = model.get_feature_importance(Pool(data[Xtrain.columns]),type=EFstrType.ShapValues,verbose=100)\n",
    "        interaction_values = best_model.get_feature_importance(Pool(SHAP_INPUT),type=EFstrType.ShapInteractionValues)\n",
    "        interaction_values=interaction_values[:,:-1,:-1]\n",
    "        shap.dependence_plot(interacted_feature, shap_values, SHAP_INPUT, interaction_index=None, show=False)\n",
    "    elif algorithm_name=='Random Forest' or algorithm_name=='Extra Tree'or algorithm_name=='Decision Tree'or algorithm_name=='AdaBoost':\n",
    "        explainer = shap.TreeExplainer(best_model,SHAP_INPUT)\n",
    "        shap_values = explainer.shap_values(X_SHAP,check_additivity= False)        \n",
    "        interaction_values = shap.TreeExplainer(best_model).shap_interaction_values(SHAP_INPUT)        \n",
    "        shap.dependence_plot(interacted_feature, shap_values, SHAP_INPUT,interaction_index=None, show=False)\n",
    "    else:\n",
    "        explainer = shap.TreeExplainer(best_model,SHAP_INPUT)\n",
    "        shap_values = explainer.shap_values(X_SHAP,check_additivity= False)\n",
    "        interaction_values = shap.TreeExplainer(best_model).shap_interaction_values(SHAP_INPUT)        \n",
    "        shap.dependence_plot(interacted_feature, shap_values, SHAP_INPUT, interaction_index=None, show=False)\n",
    "def shap_plot_interaction_ANN_single(model,interacted_feature):\n",
    "    SHAP_INPUT=raw_data.iloc[:,0:13]\n",
    "    SHAP_OUTPUT=raw_data.iloc[:,13]\n",
    "    X_SHAP=SHAP_INPUT.values.astype(np.float32)\n",
    "    y_SHAP=SHAP_OUTPUT.values.astype(np.float32)\n",
    "    explainer = shap.DeepExplainer(model,X_SHAP)\n",
    "    shap_values = explainer.shap_values(X_SHAP)\n",
    "    shap.dependence_plot(interacted_feature, shap_values[0], SHAP_INPUT, interaction_index=None, show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_plot_interaction_ANN_single(model_ANN,\"Flow Rate (mL min-1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#DC,FP,SM,FR,WC,AL,CL,IC,SC,model\n",
    "for i in np.arange(15,85,5):\n",
    "    for j in np.arange(-20,125,5):\n",
    "        processing_PRINT_ANN(i,j,0,0.3,0.27,0.05,0.1,0.54,0.045,model_ANN)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DC,FP,SM,FR,WC,AL,CL,IC,SC,model\n",
    "for i in np.arange(0.05,0.8,0.05):\n",
    "    for j in np.arange(0.05,0.8,0.05):\n",
    "        processing_PRINT_ANN(18.3,12,0,0.3,0.27,i,j,0.54,0.045,model_ANN)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DC,FP,SM,FR,WC,AL,CL,IC,SC,model\n",
    "for i in np.arange(0,2,1):\n",
    "    for j in np.arange(0,0.11,0.005):\n",
    "        processing_PRINT_ANN(18.3,12,i,0.3,0.27,0.05,0.1,0.54,j,model_ANN)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DC,FP,SM,FR,WC,AL,CL,IC,SC,model\n",
    "for i in np.arange(0,1,0.05):\n",
    "    for j in np.arange(0,4,0.05):\n",
    "        processing_PRINT_ANN(18.3,12,0,0.3,i,0.05,0.1,j,0.045,model_ANN)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DC,FP,SM,FR,WC,AL,CL,IC,SC,model\n",
    "for i in np.arange(0,1,0.01):\n",
    "    processing_PRINT_ANN(18.3,12,0,i,0.27,0.05,0.1,0.54,0.045,model_ANN)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_list1=['Dielectric Constant (C  N-1 M-2)','Flash Point(℃)']\n",
    "f_list2=['Anodic Platinum Loading Amount (mgPt cm-2)','Cathodic Platinum Loading Amount (mgPt cm-2)']\n",
    "f_list3=['Stirring Method (0 for Mechanical Stirring 1 for Ultrasound)','Solid Content (wt%)']\n",
    "f_list4=['Water Content (wt%)','I/C']\n",
    "f_index1=(0,1)\n",
    "f_index2=(5,6)\n",
    "f_index3=(2,11)\n",
    "f_index4=(4,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_plot_interaction_ANN(model_ANN,f_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_plot_interaction_ANN(model_ANN,f_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_plot_interaction_ANN(model_ANN,f_list3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_plot_interaction_ANN(model_ANN,f_list4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_ANN(DC,FP,SM,FR,WC,AL,CL,IC,SC):\n",
    "    raw_median=raw_data.median()\n",
    "    user_input1=raw_median[0:13]    \n",
    "    dict_result={}    \n",
    "    user_input1.iloc[0]=DC\n",
    "    user_input1.iloc[1]=FP\n",
    "    user_input1.iloc[2]=SM\n",
    "    user_input1.iloc[3]=FR\n",
    "    user_input1.iloc[4]=WC\n",
    "    user_input1.iloc[5]=AL\n",
    "    user_input1.iloc[6]=CL\n",
    "    user_input1.iloc[7]=IC\n",
    "    user_input1.iloc[8]=80\n",
    "    user_input1.iloc[9]=300\n",
    "    user_input1.iloc[10]=1500\n",
    "    user_input1.iloc[11]=SC\n",
    "    user_input1.iloc[12]=0.2\n",
    "    standardized_user_input1=(user_input1-np.mean(raw_data,axis=0)[0:13])/np.std(raw_data,axis=0)[0:13]\n",
    "    data_test_input1=standardized_user_input1\n",
    "    data_test_input1=pd.DataFrame(data_test_input1)\n",
    "    data_test_input1=data_test_input1.T\n",
    "    data_test_param1=data_test_input1.values.astype(np.float32)\n",
    "    predict_ann=model_ANN.predict(data_test_param1)\n",
    "    ###########result output##########\n",
    "    predict_ann=predict_ann*np.std(raw_output_global,axis=0)+np.mean(raw_output_global,axis=0)\n",
    "    x_prediction_ann=predict_ann.astype(np.float32)\n",
    "    x_prediction_ann=x_prediction_ann.tolist()\n",
    "    x_prediction_ann=x_prediction_ann[0]\n",
    "#     print(type(x_prediction_ann[0]))\n",
    "    dict_result.update({x_prediction_ann[0]:{'Dielectric Constant (C  N-1 M-2)':DC,'Flash Point(℃)':FP}})\n",
    "#     print(DC,FP,SM,FR,AL,CL,SC,x_prediction_ann[0])\n",
    "\n",
    "    return x_prediction_ann[0], dict_result\n",
    "def processing_func(p):\n",
    "    DC,FP,SM,FR,WC,AL,CL,IC,SC= p\n",
    "    result, _ = processing_ANN(DC,FP,SM,FR,WC,AL,CL,IC,SC)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "from sko.GA import GA\n",
    "from sko.DE import DE\n",
    "%matplotlib\n",
    "iter_num = 32\n",
    "ga = GA(func=processing_func, n_dim=7, size_pop=50, max_iter=iter_num, lb=[15,-20,0,0,0.05,0.1,0], ub=[80,120,1,1,0.75,0.75,0.105],precision=1e-2)\n",
    "import time\n",
    "time_start = time.time()\n",
    "best_x, best_y = ga.run()\n",
    "print('best_x:', best_x, '\\n', 'best_y:', best_y)\n",
    "time_end = time.time()\n",
    "print('Time cost of grid search= %fs' % (time_end - time_start))\n",
    "\n",
    "# visualization \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Y_history = pd.DataFrame(ga.all_history_Y)\n",
    "fig, ax = plt.subplots(2, 1, figsize=(6, 9))\n",
    "ax[0].plot(Y_history.index, Y_history.values, '.', color='red')\n",
    "Y_history.min(axis=1).cummin().plot(kind='line')\n",
    "plt.show()\n",
    "plt.savefig('GA OPT ANN SEL.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=17\n",
    "X_train, X_test, y_train, y_test = train_test_split(raw_input, raw_output, test_size=.15,random_state=seed)\n",
    "standardized_data = (raw_data-np.mean(raw_data,axis=0))/np.std(raw_data,axis=0)\n",
    "raw_input_global=raw_data.iloc[:,0:13]\n",
    "raw_output_global=raw_data.iloc[:,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "##########CatBoost gridsearch CV for best hyperparameter##########\n",
    "model_CatRegressor=catboost.CatBoostRegressor(random_state=1,verbose=0)\n",
    "param_cat = {\n",
    " 'learning_rate':[0.16],\n",
    " 'n_estimators':[50],\n",
    " 'max_depth':[5],\n",
    " 'subsample':[0.4],\n",
    "    'reg_lambda':[0.0001]\n",
    "}\n",
    "CAT=gridsearch(model_CatRegressor,param_cat,'CatBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pdp_single_else(model_CatRegressor,param_cat,'Flow Rate (mL min-1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_plot_interaction_single(model_CatRegressor,param_cat,'CatBoost','Flow Rate (mL min-1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DC,FP,SM,FR,WC,AL,CL,IC,SC,model\n",
    "for i in np.arange(15,85,5):\n",
    "    for j in np.arange(-20,125,5):\n",
    "        processing_PRINT_OTHER(i,j,0,0.3,0.27,0.05,0.1,0.54,0.045,CAT)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DC,FP,SM,FR,WC,AL,CL,IC,SC,model\n",
    "for i in np.arange(0.05,0.8,0.05):\n",
    "    for j in np.arange(0.05,0.8,0.05):\n",
    "        processing_PRINT_OTHER(18.3,12,0,0.3,0.27,i,j,0.54,0.045,CAT)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DC,FP,SM,FR,WC,AL,CL,IC,SC,model\n",
    "for i in np.arange(0,2,1):\n",
    "    for j in np.arange(0,0.11,0.005):\n",
    "        processing_PRINT_OTHER(18.3,12,i,0.3,0.27,0.05,0.1,0.54,j,CAT)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DC,FP,SM,FR,WC,AL,CL,IC,SC,model\n",
    "for i in np.arange(0,1,0.05):\n",
    "    for j in np.arange(0,4,0.05):\n",
    "        processing_PRINT_OTHER(18.3,12,0,0.3,i,0.05,0.1,j,0.045,CAT)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DC,FP,SM,FR,WC,AL,CL,IC,SC,model\n",
    "for i in np.arange(0,1,0.01):\n",
    "    processing_PRINT_OTHER(18.3,12,0,i,0.27,0.05,0.1,0.54,0.045,CAT)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_plot_interaction(model_CatRegressor,param_cat,'CatBoost',f_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_plot_interaction(model_CatRegressor,param_cat,'CatBoost',f_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_plot_interaction(model_CatRegressor,param_cat,'CatBoost',f_list3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_plot_interaction(model_CatRegressor,param_cat,'CatBoost',f_list4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdp_plot_2d_XG_CAT(model_CatRegressor,param_cat,f_index1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdp_plot_2d_XG_CAT(model_CatRegressor,param_cat,f_index2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdp_plot_2d_XG_CAT(model_CatRegressor,param_cat,f_index3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdp_plot_2d_XG_CAT(model_CatRegressor,param_cat,f_index4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "###########GradientBoost gridsearch CV for best hyperparameter##########\n",
    "model_GradientBoostingRegressor = ensemble.GradientBoostingRegressor(random_state=1)\n",
    "###########defining the parameters dictionary##########\n",
    "param_GB = {\n",
    " 'learning_rate':[0.2],\n",
    "                'criterion':['mae'],\n",
    "                 'max_features':['sqrt'],\n",
    "                 'loss':['ls'],\n",
    "    'max_depth':[3]\n",
    "}\n",
    "GB=gridsearch(model_GradientBoostingRegressor,param_GB,'GradientBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_plot_interaction_single(model_GradientBoostingRegressor,param_GB,'Gradient Boost','Flow Rate (mL min-1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pdp_single_else(model_GradientBoostingRegressor,param_GB,'Flow Rate (mL min-1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_plot_interaction(model_GradientBoostingRegressor,param_GB,'GradientBoost',f_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_plot_interaction(model_GradientBoostingRegressor,param_GB,'GradientBoost',f_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_plot_interaction(model_GradientBoostingRegressor,param_GB,'GradientBoost',f_list3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_plot_interaction(model_GradientBoostingRegressor,param_GB,'GradientBoost',f_list4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdp_plot_2d(model_GradientBoostingRegressor,param_GB,f_index1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdp_plot_2d(model_GradientBoostingRegressor,param_GB,f_index2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdp_plot_2d(model_GradientBoostingRegressor,param_GB,f_index3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdp_plot_2d(model_GradientBoostingRegressor,param_GB,f_index4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DC,FP,SM,FR,WC,AL,CL,IC,SC,model\n",
    "for i in np.arange(15,85,5):\n",
    "    for j in np.arange(-20,125,5):\n",
    "        processing_PRINT_OTHER(i,j,0,0.3,0.27,0.05,0.1,0.54,0.045,GB)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DC,FP,SM,FR,WC,AL,CL,IC,SC,model\n",
    "for i in np.arange(0.05,0.8,0.05):\n",
    "    for j in np.arange(0.05,0.8,0.05):\n",
    "        processing_PRINT_OTHER(18.3,12,0,0.3,0.27,i,j,0.54,0.045,GB)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DC,FP,SM,FR,WC,AL,CL,IC,SC,model\n",
    "for i in np.arange(0,2,1):\n",
    "    for j in np.arange(0,0.11,0.005):\n",
    "        processing_PRINT_OTHER(18.3,12,i,0.3,0.27,0.05,0.1,0.54,j,GB)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DC,FP,SM,FR,WC,AL,CL,IC,SC,model\n",
    "for i in np.arange(0,1,0.05):\n",
    "    for j in np.arange(0,4,0.05):\n",
    "        processing_PRINT_OTHER(18.3,12,0,0.3,i,0.05,0.1,j,0.045,GB)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DC,FP,SM,FR,WC,AL,CL,IC,SC,model\n",
    "for i in np.arange(0,1,0.01):\n",
    "    processing_PRINT_OTHER(18.3,12,0,i,0.27,0.05,0.1,0.54,0.045,GB)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
